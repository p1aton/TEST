---
layout: post
title:  "Gradient Boosting Notes and Pictures"
crawlertitle: "Hari's talk"
summary: "Info about the talk"
date:   2017-06-16 12:09:47 +0700
categories: posts
tags: ['Meetings Resources and summary']
author: Felipe
---

On Friday June 16 [Dr. Ravindran](https://www.linkedin.com/in/hariar/) gave a talk on gradient boosting. The key points to remember are:

- Boosting is a technique to create strong classifiers out of weaker ones. 
- The first boosting algorithm, designed in the 80's?, is Adaboost. It consists on creating some weights for each classifier that contain enough info about their perfomarnce.  
- Great out of the bag classifiers.
- You can find the slides from the talk [here]().

## Pics from the talk: 

<center>
<img src="{{ '/assets/images/16-06-2017/photo1.jpg' | prepend: site.baseurl }}" alt=""> 
</center>

<center>
<img src="{{ '/assets/images/16-06-2017/photo2.jpg' | prepend: site.baseurl }}" alt=""> 
</center>



<center>
<img src="{{ '/assets/images/16-06-2017/photo3.jpg' | prepend: site.baseurl }}" alt=""> 
</center>



<center>
<img src="{{ '/assets/images/16-06-2017/photo4.jpg' | prepend: site.baseurl }}" alt=""> 
</center>



<center>
<img src="{{ '/assets/images/16-06-2017/photo5.jpg' | prepend: site.baseurl }}" alt=""> 
</center>


