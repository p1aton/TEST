I"X<p>On Friday June 16 <a href="https://www.linkedin.com/in/hariar/">Dr. Ravindran</a> gave a talk on gradient boosting. The key points to remember are:</p>

<ul>
  <li>Boosting is a technique to create strong classifiers out of weaker ones.</li>
  <li>The first boosting algorithm, designed in the 80â€™s?, is Adaboost. It consists on creating some weights for each classifier that contain enough info about their perfomarnce.</li>
  <li>Great out of the bag classifiers.</li>
  <li>You can find the slides from the talk <a href="">here</a>.</li>
</ul>

<h2 id="pics-from-the-talk">Pics from the talk:</h2>

<center>
<img src="/dataerudite.github.io/assets/images/16-06-2017/photo1.jpg" alt="" /> 
</center>

<center>
<img src="/dataerudite.github.io/assets/images/16-06-2017/photo2.jpg" alt="" /> 
</center>

<center>
<img src="/dataerudite.github.io/assets/images/16-06-2017/photo3.jpg" alt="" /> 
</center>

<center>
<img src="/dataerudite.github.io/assets/images/16-06-2017/photo4.jpg" alt="" /> 
</center>

<center>
<img src="/dataerudite.github.io/assets/images/16-06-2017/photo5.jpg" alt="" /> 
</center>

:ET